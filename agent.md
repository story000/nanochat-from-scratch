# nanochat Lab 产品文档

## 1. 产品概述
- 面向初学者的交互式实验室，循序渐进拆解 nanochat，从分词到 Web UI，全链路“手撕”实现。
- 每个模块包含：目标讲解 → 代码任务 → 对比标准答案 → 自动测试 → 反思问答。
- 支持在浏览器中写代码、运行测试、查看差异，降低学习曲线。

## 2. 学习者画像与核心场景
- **目标用户**：具备 Python/PyTorch 基础、想理解 LLM 全流程的高校/培训学习者。
- **主要诉求**
  - 清晰的模块划分，避免一次面对全量复杂度。
  - 边学边做，立刻验证代码正确性。
  - 能够观察不同实现策略带来的性能/质量差异。
- **使用路径**
  - 登录 → 选择学习路线 → 阅读导学 → 编码练习 → 查看测试报告 → 记录心得 → 解锁下一模块。

## 3. 学习路径设计
1. **迎新与环境准备**
   - 目标：理解 nanochat 总览、熟悉在线环境。
   - 任务：通过 UI 了解仓库结构、运行最小 demo。
   - 测试：检测依赖、执行 `hello nanochat` 练习。

2. **Tokenizer 基础**
   - 目标：复现 BPE 训练与分词流程。
   - 关键文件：`rustbpe/src/lib.rs`, `nanochat/tokenizer.py`.
   - 任务：实现 tokenization API；比较 Rust/Python 版性能。
   - 测试：压缩率、逆变换正确性、常见 bug 检测。

3. **数据集获取与整理**
   - 目标：掌握 `nanochat/dataset.py` 中的数据下载、拆分、混洗逻辑。
   - 任务：实现数据分片管理、缓存策略。
   - 测试：对指定储存路径执行 `python -m nanochat.dataset`，检查元数据。

4. **数据加载与分布式切分**
   - 目标：实现 `nanochat/dataloader.py` 的 tokenizing loader、分布式 shard 同步。
   - 任务：手写迭代器、处理 padding、跨 GPU 同步。
   - 测试：模拟 1/8 GPU 场景，验算样本覆盖率与 batch 等价性。

5. **模型骨架 (Transformer)**
   - 目标：拆解 `nanochat/gpt.py`，实现 Attention、MLP、LayerNorm 等组件。
   - 任务：逐层补全模块，验证参数量与 forward shape。
   - 测试：单元测试 + 基准权重比对 + `torch.fx` 图结构审查。

6. **优化器 (AdamW / Muon)**
   - 目标：理解自定义分布式优化器 (`nanochat/adamw.py`, `nanochat/muon.py`)。
   - 任务：实现参数更新、权重平均、梯度累积策略。
   - 测试：和 PyTorch 官方 Optimizer 对拍、截断误差分析。

7. **基础训练循环**
   - 目标：掌握 `scripts/base_train.py` 的训练主循环、配置管理。
   - 任务：填充步进逻辑、日志、checkpoint。
   - 测试：跑一个 tiny 配置，用 loss 曲线、梯度统计验证收敛。

8. **Mid-Training 适配**
   - 目标：理解 mid 阶段特定数据混合与损失权重。
   - 任务：编写数据重采样、学习率 schedule 调整。
   - 测试：对比 base vs mid 评测指标，输出差异解读。

9. **SFT (指令微调)**
   - 目标：实现 SFT pipeline (`scripts/chat_sft.py`)，整合对话格式。
   - 任务：构造 prompt 模板、实现对齐损失。
   - 测试：自动化 prompt 生成、sanity check 生成质量。

10. **RL (可选)**
    - 目标：理解 `scripts/chat_rl.py`，实现 PPO/奖励计算。
    - 任务：补全策略更新、价值网络推理。
    - 测试：运行小规模 RL 回合，观察 reward 曲线。

11. **推理引擎与 KV Cache**
    - 目标：实现 `nanochat/engine.py` 中的高效推理。
    - 任务：完成 KV cache 管理、批量采样、temperature/top-p 控制。
    - 测试：对同 prompt 进行生成比对，测延迟与吞吐。

12. **工具调用 (execution.py)**
    - 目标：理解模型执行 Python 代码的机制。
    - 任务：实现安全沙箱、结果注入模型回复。
    - 测试：运行评测脚本，检查安全限制与字串拼接。

13. **评测任务体系**
    - 目标：掌握 `tasks/` 目录设计，运行 CORE/MMLU/GSM8K 等。
    - 任务：实现通用 Task wrapper、指标汇总。
    - 测试：自动生成报告，比较 baseline 与自定义模型表现。

14. **Web UI 与部署**
    - 目标：实现 `nanochat/ui.html` + `scripts/chat_web.py`，理解全栈流程。
    - 任务：补全前端组件、Websocket 或 HTTP API、session 管理。
    - 测试：手动对话、截图比对、网络日志检查。

15. **报告生成与分析**
    - 目标：理解 `nanochat/report.py`，自动生成 `report.md`。
    - 任务：完成指标收集、图表绘制、结论生成。
    - 测试：对速度 vs 质量进行分析，输出完整报告。

16. **综合项目 (Capstone)**
    - 目标：综合改造模型（例如定制人格）。
    - 任务：自由发挥，构建编排脚本、撰写总结。
    - 测试：Peer review + 设计问答。

## 4. 前端交互设计

### 4.1 学习仪表盘
- 模块地图：展示 16 个模块的解锁顺序与进度。
- 成果总览：最近测试结果、待复习模块、笔记入口。
- 里程碑提示：完成关键节点触发提醒与奖励（如证书、徽章）。

### 4.2 模块页面结构
- **导学区**：短视频/图文说明、目标与前置知识。
- **代码演练区**
  - 双栏布局：左侧任务说明 + 代码片段、右侧为交互式编辑器。
  - 提供内置编辑器（Monaco）：语法高亮、补全、lint、格式化。
  - “一键对比”按钮：展示学习者提交与标准答案差异（行级 diff）。
  - “查看提示”：渐进式提示（层层开放）或参考资料链接。
- **测试区**
  - 按钮触发测试，实时展示 stdout/stderr、性能指标。
  - 自动评语：聚焦错误信息、建议下一步修复。
  - 支持多次尝试并保留历史记录。
- **反思总结**
  - 标准问题：实现难点、优化空间、对比标准方案的体会。
  - 支持上传笔记或生成学习日志。
- **解锁条件**
  - 测试通过 + 反思提交后才能进入下一模块。

### 4.3 左侧全局导航
- “路线图”、“我的进度”、“参考资料”、“讨论区”、“个人设置”。
- 支持全局搜索模块/术语。

### 4.4 代码对比体验优化
- Live diff：支持 highlight 变化、折叠不相关行。
- “逐步对比”模式：按照任务拆分不同小节进行对比，避免信息过载。
- “性能对比”视图：展示基础实现 vs 优化实现的指标差异图表。

### 4.5 测试与实验结果可视化
- 折线图：loss、准确率曲线。
- 雷达图：多任务评测结果。
- 热力图：不同配置对性能的影响。
- 交互式日志：点击时间节点跳转到运行日志、模型输出。

### 4.6 社区互动与导师支持
- 模块内讨论区（线程式），可发布问题、分享改进方案。
- “导师点评”入口：提交代码可请求辅导老师反馈。
- 强调尊重原创，鼓励描述思考过程。

## 5. 内容制作与技术实现

### 5.1 内容产出流程
- 每个模块需准备：导学材料、任务描述、标准答案、测试脚本、常见错误解析。
- 建议采用 Jupyter/Markdown 先行撰写，再移植到平台。
- 维护版本：跟随 upstream nanochat 重要更新同步调整。

### 5.2 后端与评测架构
- 容器化安全沙箱，限制 CPU/GPU/网络资源，防止恶意代码。
- 支持自定义脚本运行（Python/Rust），可选轻量 GPU（例如用于 infer）。
- 测试框架：pytest + 自定义 CLI，标准化输出 JSON，供前端渲染。
- 代码存储：Git-based（每个用户 fork 一份）或数据库版本管理。
- 检测抄袭：对比提交与标准答案的结构相似度，提示学习者自查。

### 5.3 进度与成就系统
- 进度持久化：记录每次测试结果、耗时、日志。
- 成就徽章示例：完成 tokenizer、首次跑通 mid、完成 RL 选修等。
- 周报/学习时间统计，鼓励坚持。

## 6. 评估指标与迭代计划
- **核心指标**
  - 模块完成率、平均尝试次数、测试通过率。
  - 学习者自评信心（前后对比）。
  - 平台留存（7 日 / 30 日）。
- **用户反馈收集**
  - 每模块后微调查：难度、帮助程度。
  - 讨论区、客服工单分析常见问题。
- **迭代节奏**
  - Beta：先发布 Tokenizer + Dataset + Model 基础 6 个模块。
  - 收集数据 → 调整任务粒度/提示。
  - 后续逐步上线 mid/SFT/RL、高阶模块。
  - 定期同步 nanochat upstream 改动。

## 7. 风险与应对
- **技术更新频繁**：建立版本差异跟踪机制，文档保持同步。
- **学习者流失**：通过预热课程、低门槛“爽感”任务、激励机制提升粘性。
- **测试资源开销**：限制长时间训练；提供预生成数据/模型，重点在理解逻辑。
- **安全风险**：沙箱严格隔离，代码审计；禁止外部网络访问。

## 8. 推广与合作
- 面向高校开设工作坊，结合教学计划。
- 与社区/Kaggle 等合作，举办微型竞赛（如优化 mid 模型表现）。
- 分享博客/直播，演示模块体验，吸引开发者加入。

---

这份文档可以作为产品设计的初版框架，后续可在每个模块中再补充更详细的任务拆分、示例代码与测试规范。
